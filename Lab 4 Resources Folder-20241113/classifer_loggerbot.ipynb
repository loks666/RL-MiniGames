{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to train a neural network based on our loggerbot's csv output\n",
    "\n",
    "First we load the log file in csv format.  This assumes our columns are stored in the order exactly as below, and also that there is no contamination (e.g. other print statements) in the csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# This assumes we've copied the log file (\"LoggerBot.log\") into our current working folder...\n",
    "df0=pd.read_csv(\"LoggerBot.log\",names=[\"Turn\",\"Try\",\"PlayerID\",\"PlayerName\",\"MissionsBeenOn\",\"FailedMissionsBeenOn\",\"VotedUp0\",\"VotedUp1\",\"VotedUp2\",\"VotedUp3\",\"VotedUp4\",\"VotedUp5\",\"VotedDown0\",\"VotedDown1\",\"VotedDown2\",\"VotedDown3\",\"VotedDown4\",\"VotedDown5\",\"Spy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This next line just prints the first 5 rows of the loaded data, df0, which is a pandas dataframe object\n",
    "print(df0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a subset of the data which only corresponds to the player \"Bounder\", \n",
    "# since bounder is hopefully quite representitive of a good player.  This decision to use only one bot\n",
    "# might not be optimal, but it simplifies things for now.\n",
    "df=df0.query(\"PlayerName=='Bounder'\") # we can filter a pandas dataframe very nicely like an SQL query!\n",
    "print(df.head()) #print the filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe()) # print some key column information\n",
    "# This lets us visually inspect the columns to check there's no nan values in there or infinity values,\n",
    "# or anything else showing signs of data corruption...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "x_train=df.values[:,4:18].astype(np.float32) # This filters out only the columns we want to use as input vector for our NN.\n",
    "# Note [:,4:18] only includes columns 4 to 17 inclusive (it does not include column 18)\n",
    "y_train=df.values[:,18].astype(np.int32) # This is our target column.\n",
    "print(y_train.shape) # This is just a rank 1 array.\n",
    "print(y_train[0:6]) # first 6 entries of y.  Should be all 1s and zeros\n",
    "print(x_train[0:6]) # first 6 rows of x, our input vectors.\n",
    "num_inputs=x_train.shape[1] # this works out how many columns there are in x, i.e. how many inputs our network needs.\n",
    "num_outputs=2 # Two outputs needed - for \"spy\" or \"not spy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into a training data set and a validation dataset.\n",
    "dataset_size=len(x_train)\n",
    "train_set_size=int(dataset_size*0.7) # choose 70% of the data for training and 30% for validation\n",
    "x_val,y_val=x_train[train_set_size:],y_train[train_set_size:]\n",
    "x_train,y_train=x_train[:train_set_size],y_train[:train_set_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a keras model:\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define Sequential model with 3 layers\n",
    "model = keras.Sequential(name=\"my_neural_network\")\n",
    "layer1=layers.Dense(10, activation=\"tanh\", input_shape=(num_inputs,))\n",
    "model.add(layer1)\n",
    "layer2=layers.Dense(10, activation=\"tanh\")\n",
    "model.add(layer2)\n",
    "layer3=layers.Dense(num_outputs, activation=\"softmax\")\n",
    "model.add(layer3)\n",
    "\n",
    "print(model(x_train[0:3])) # just check the NN is the correct shape for our training data, and see what comes out of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the usual business for keras training\n",
    "# It's a classification problem , so we need cross entropy here.\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.001),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the usual business for keras training\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=50,\n",
    "    epochs=120,\n",
    "    validation_data=(x_val, y_val),verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our training curves. This is always important to see if we've started to overfit or whether \n",
    "# we could benefit from more training cycles....\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"],label=\"Validation Set Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# The following graph should show about 77% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate base rate accuracy\n",
    "print(y_train.mean())\n",
    "# This shows us what accuracy we could get if we just guess the same thing all the time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this game, since there are always 2 spies randomly chosen from a team of 5,  that is 2/5=40% of the time we could guess someone is a spy.  This matches the base rate above, very closely.   \n",
    "\n",
    "- However if we just wanted a simple fixed classifer to make the best fixed guess, by just saying  \"Not Spy\" all of the time we could score a whopping 60% accuracy!  So if our classifier can't beat  60% then we can say that it is rubbish.\n",
    "- Fortunately our classifer is scoring over 70% accuracy comfortably (as should be shown in the graph above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the next code block, I'd like to work out if our neural network's accuracy improves during each game.\n",
    "- For example, once we've seen several rounds of play we gather more clues as to who is a spy, so our accuracy should increase as each game goes on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_by_turn=[]\n",
    "maximum_turn=df['Turn'].max()\n",
    "accuracy_metric=tf.keras.metrics.Accuracy()\n",
    "print(\"maximum_turn\",maximum_turn)\n",
    "for turn in range(1,maximum_turn+1):\n",
    "    df_restricted=df.query('Turn>='+str(turn)) # Pull out just those rows of the training data corresponding to later turns in the game\n",
    "    \n",
    "    x=df_restricted.values[:,4:18].astype(np.float32)\n",
    "    y=df_restricted.values[:,18].astype(np.int32)\n",
    "    y_guess=model(x)\n",
    "    y_guess=tf.argmax(y_guess,axis=1)\n",
    "    #accuracy=tf.reduce_mean(tf.cast(tf.equal(y,y_guess),tf.float32)) # This formula owuld also give us the accuracy but this is hand-evaluated.\n",
    "    accuracy=accuracy_metric(y_guess,y) # This function calculates accuracy using an in-built keras function.\n",
    "    accuracy_by_turn.append(accuracy.numpy()) # record the results so we can plot them.\n",
    "print(tf.range(maximum_turn),accuracy_by_turn)\n",
    "plt.plot(tf.range(1,1+len(accuracy_by_turn)),accuracy_by_turn)\n",
    "plt.title('Accuracy at identifying whether \"Bounder\" is a spy as the game progresses')\n",
    "plt.xlabel('Turn')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, save our model so we can build a resistance-bot that plays using this neural network.\n",
    "model.save('loggerbot_classifier.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
